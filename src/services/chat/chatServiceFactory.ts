
import { ChatService, ChatServiceOptions, FileAttachment, GeminiChatService } from './types';
import { getChatService as getGeminiChatService } from './googleGenAIService';

export enum ChatServiceProvider {
  GEMINI = 'gemini',
  OPENAI = 'openai',
  MOCK = 'mock',
}

interface ChatServiceFactoryOptions extends ChatServiceOptions {
  provider: ChatServiceProvider;
}

/**
 * Factory function to create a chat service based on the provider
 */
export function createChatService(options: ChatServiceFactoryOptions): ChatService {
  const { provider, ...serviceOptions } = options;
  
  switch (provider) {
    case ChatServiceProvider.GEMINI:
      return getGeminiChatService(serviceOptions);
    case ChatServiceProvider.OPENAI:
      // This would be implemented later
      console.warn('OpenAI provider not yet implemented, falling back to mock');
      return createMockChatService(serviceOptions);
    case ChatServiceProvider.MOCK:
    default:
      return createMockChatService(serviceOptions);
  }
}

/**
 * Create a mock chat service for testing/demo
 */
function createMockChatService(options: ChatServiceOptions): ChatService {
  return new MockChatService(options);
}

/**
 * Mock implementation of a chat service
 */
class MockChatService implements ChatService {
  private apiKey: string;
  private modelName: string;
  private temperature: number;
  private maxTokens: number;
  private messageHistory: any[] = [];

  constructor(options: ChatServiceOptions) {
    this.apiKey = options.apiKey;
    this.modelName = options.modelName || 'mock-model';
    this.temperature = options.temperature || 0.7;
    this.maxTokens = options.maxTokens || 1024;
    
    console.log(`Initialized Mock Chat Service with model: ${this.modelName}`);
  }

  async sendMessage(message: string, history?: any[], files?: FileAttachment[]): Promise<any> {
    console.log(`Mock: Sending message: ${message}`);
    
    if (history) {
      this.messageHistory = [...history];
    }
    
    const userMessage = {
      role: 'user',
      content: message,
      timestamp: Date.now()
    };
    
    this.messageHistory.push(userMessage);
    
    // Generate a mock response based on the message
    return new Promise((resolve) => {
      setTimeout(() => {
        let responseContent = '';
        
        // If files are provided, mention them in the response
        if (files && files.length > 0) {
          responseContent = `I've received your message along with ${files.length} file(s). `;
        }
        
        // Generate different responses based on the message content
        if (message.toLowerCase().includes('hello') || message.toLowerCase().includes('hi')) {
          responseContent += 'Hello there! How can I help you today?';
        } else if (message.toLowerCase().includes('help')) {
          responseContent += 'I\'m here to help! You can ask me questions about AI services, automation, or consulting.';
        } else if (message.toLowerCase().includes('service') || message.toLowerCase().includes('offering')) {
          responseContent += 'We offer a range of AI services including chatbot development, workflow automation, and strategic consulting.';
        } else if (message.toLowerCase().includes('contact') || message.toLowerCase().includes('book')) {
          responseContent += 'You can book a consultation by using the booking calendar on our site or by sending a message through the contact form.';
        } else {
          responseContent += `This is a mock response to your message: "${message}". In a real implementation, this would be generated by an AI service.`;
        }
        
        const response = {
          role: 'assistant',
          content: responseContent,
          timestamp: Date.now()
        };
        
        this.messageHistory.push(response);
        resolve(response);
      }, 1500); // Simulate network delay
    });
  }

  clearHistory(): void {
    console.log('Clearing chat history in mock service');
    this.messageHistory = [];
  }
}
